{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13198517,"sourceType":"datasetVersion","datasetId":8364530}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename)) \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-30T14:07:50.667404Z","iopub.execute_input":"2025-09-30T14:07:50.667830Z","iopub.status.idle":"2025-09-30T14:07:50.684682Z","shell.execute_reply.started":"2025-09-30T14:07:50.667795Z","shell.execute_reply":"2025-09-30T14:07:50.683668Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ml4cpsp1/train.json\n/kaggle/input/ml4cpsp1/test.json\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T14:07:50.686238Z","iopub.execute_input":"2025-09-30T14:07:50.686585Z","iopub.status.idle":"2025-09-30T14:07:50.712633Z","shell.execute_reply.started":"2025-09-30T14:07:50.686559Z","shell.execute_reply":"2025-09-30T14:07:50.711718Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\n\n# ===================== DATA PREPROCESSING ========================\ndf_train = pd.read_json('/kaggle/input/ml4cps/train.json').T\ndf_test = pd.read_json('/kaggle/input/ml4cps/test.json').T\n\ndef ensure_list(x): return x if isinstance(x, list) else [x]\ndf_train['contributor'] = df_train['contributor'].apply(ensure_list)\ndf_test['contributor'] = df_test['contributor'].apply(ensure_list)\n\nvenue_contrib_history, year_contrib_history, coauthor_counts = {}, {}, {}\nfor _, row in df_train.iterrows():\n    venue, year, contribs = row['article_venue'], row['article_year'], row['contributor']\n    for c in contribs:\n        venue_contrib_history.setdefault(c, {}).setdefault(venue, 0)\n        venue_contrib_history[c][venue] += 1\n        year_contrib_history.setdefault(c, {}).setdefault(year, 0)\n        year_contrib_history[c][year] += 1\n    for c1 in contribs:\n        for c2 in contribs:\n            if c1 != c2:\n                coauthor_counts.setdefault(c1, {}).setdefault(c2, 0)\n                coauthor_counts[c1][c2] += 1\n\ndef expand_positives(df):\n    rows = []\n    for _, row in df.iterrows():\n        all_cont = row['contributor']\n        for c in all_cont:\n            other_cont = [x for x in all_cont if x != c]\n            rows.append({'article_id': row['id'], 'article_venue': row['article_venue'], 'article_year': row['article_year'],\n                         'text': row['text'], 'candidate': c, 'contributor': other_cont, 'label': 1})\n    return pd.DataFrame(rows)\n\ndef generate_negatives(df, all_contrib, n_neg=2, seed=42):\n    rng = np.random.default_rng(seed)\n    negs = []\n    for _, row in df.iterrows():\n        true_cont = set(row['contributor'])\n        possible_negs = list(all_contrib - true_cont)\n        sampled = rng.choice(possible_negs, size=min(n_neg, len(possible_negs)), replace=False)\n        for c in sampled:\n            negs.append({'article_id': row['id'], 'article_venue': row['article_venue'], 'article_year': row['article_year'],\n                         'text': row['text'], 'candidate': c, 'contributor': list(true_cont), 'label': 0})\n    return pd.DataFrame(negs)\n\ndf_train_pos = expand_positives(df_train)\nall_contrib = set([c for sublist in df_train['contributor'] for c in sublist])\ndf_train_neg = generate_negatives(df_train, all_contrib)\ndf_train_full = pd.concat([df_train_pos, df_train_neg], ignore_index=True)\n\ndef to_joined_string(x):\n    if isinstance(x, list): return \" \".join(map(str, x))\n    else: return str(x)\ndf_train_full['text_str'] = df_train_full['text'].apply(to_joined_string)\ndf_train_full['cont_str'] = df_train_full['contributor'].apply(to_joined_string)\ndf_test['text_str'] = df_test['text'].apply(to_joined_string)\ndf_test['cont_str'] = df_test['contributor'].apply(to_joined_string)\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\nvectorizer_text = TfidfVectorizer(max_features=600, ngram_range=(1,2), analyzer='word')\nvectorizer_cont = TfidfVectorizer(max_features=300, ngram_range=(1,2), analyzer='word')\n\nTfidf_text_train = vectorizer_text.fit_transform(df_train_full['text_str'])\nTfidf_cont_train = vectorizer_cont.fit_transform(df_train_full['cont_str'])\nTfidf_text_test = vectorizer_text.transform(df_test['text_str'])\nTfidf_cont_test = vectorizer_cont.transform(df_test['cont_str'])\n\ndf_train_full['article_venue'] = df_train_full['article_venue'].astype(str).replace('', 'missing')\ndf_test['article_venue'] = df_test['article_venue'].astype(str).replace('', 'missing')\nohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\nvenue_ohe_train = ohe.fit_transform(df_train_full[['article_venue']])\nvenue_ohe_test = ohe.transform(df_test[['article_venue']])\nvenue_cols = ohe.get_feature_names_out(['article_venue'])\nvenue_df_train = pd.DataFrame(venue_ohe_train, columns=venue_cols, index=df_train_full.index)\nvenue_df_test = pd.DataFrame(venue_ohe_test, columns=venue_cols, index=df_test.index)\n\ndef add_hist_features(row):\n    c, venue, year, conts = row['candidate'], row['article_venue'], row['article_year'], row['contributor']\n    venue_count = venue_contrib_history.get(c, {}).get(venue, 0)\n    year_count = year_contrib_history.get(c, {}).get(year, 0)\n    coauthor_count = sum(coauthor_counts.get(c, {}).get(other, 0) for other in conts)\n    uniq_words = len(set(row['text_str'].split()))\n    num_contrib = len(row['contributor'])\n    text_len = len(row['text_str'])\n    return pd.Series([venue_count, year_count, coauthor_count, uniq_words, num_contrib, text_len])\n\nmeta_cols = ['venue_count', 'year_count', 'coauthor_count', 'uniq_words', 'num_contrib', 'text_len']\ndf_train_full[meta_cols] = df_train_full.apply(add_hist_features, axis=1)\ndf_test[meta_cols] = df_test.apply(\n    lambda r: pd.Series([\n        venue_contrib_history.get(r['candidate'], {}).get(r['article_venue'], 0),\n        year_contrib_history.get(r['candidate'], {}).get(r['article_year'], 0),\n        sum(coauthor_counts.get(r['candidate'], {}).get(other, 0) for other in r['contributor']),\n        len(set(r['text_str'].split())),\n        len(r['contributor']),\n        len(r['text_str'])\n    ]), axis=1)\n\nscaler = StandardScaler()\nhist_train = scaler.fit_transform(df_train_full[meta_cols])\nhist_test = scaler.transform(df_test[meta_cols])\nhist_df_train = pd.DataFrame(hist_train, columns=meta_cols, index=df_train_full.index)\nhist_df_test = pd.DataFrame(hist_test, columns=meta_cols, index=df_test.index)\n\ntfidf_text_train_df = pd.DataFrame(Tfidf_text_train.toarray(), columns=[f\"text__{f}\" for f in vectorizer_text.get_feature_names_out()], index=df_train_full.index)\ntfidf_cont_train_df = pd.DataFrame(Tfidf_cont_train.toarray(), columns=[f\"cont__{f}\" for f in vectorizer_cont.get_feature_names_out()], index=df_train_full.index)\ntfidf_text_test_df = pd.DataFrame(Tfidf_text_test.toarray(), columns=[f\"text__{f}\" for f in vectorizer_text.get_feature_names_out()], index=df_test.index)\ntfidf_cont_test_df = pd.DataFrame(Tfidf_cont_test.toarray(), columns=[f\"cont__{f}\" for f in vectorizer_cont.get_feature_names_out()], index=df_test.index)\n\ntrain_features = pd.concat([venue_df_train.reset_index(drop=True), hist_df_train.reset_index(drop=True), \n                            tfidf_text_train_df.reset_index(drop=True), tfidf_cont_train_df.reset_index(drop=True)], axis=1)\ntest_features = pd.concat([venue_df_test.reset_index(drop=True), hist_df_test.reset_index(drop=True), \n                           tfidf_text_test_df.reset_index(drop=True), tfidf_cont_test_df.reset_index(drop=True)], axis=1)\n\nfor col in train_features.columns:\n    if col not in test_features.columns: test_features[col] = 0\nfor col in list(test_features.columns):\n    if col not in train_features.columns: test_features.drop(columns=col, inplace=True)\ntest_features = test_features[train_features.columns]\nX = train_features.values.astype(np.float32)\ny = df_train_full['label'].values.astype(int)\nX_test = test_features.values.astype(np.float32)\n\n# ========== FAST ENSEMBLE TRAINING & PREDICTION ==========\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)\n\n# XGBoost\nxgb_model = xgb.XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.037, subsample=0.9,\n    colsample_bytree=0.8, reg_alpha=0.5, reg_lambda=2.0, n_jobs=-1, verbosity=1, random_state=42)\nxgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=30, verbose=100)\nxgb_val = xgb_model.predict_proba(X_val)[:,1]\nxgb_test = xgb_model.predict_proba(X_test)[:,1]\n\n# RandomForest\nrf_model = RandomForestClassifier(n_estimators=120, max_depth=11, n_jobs=-1, random_state=42)\nrf_model.fit(X_train, y_train)\nrf_val = rf_model.predict_proba(X_val)[:,1]\nrf_test = rf_model.predict_proba(X_test)[:,1]\n\n# Logistic Regression\nlr_model = LogisticRegression(max_iter=600, random_state=42)\nlr_model.fit(X_train, y_train)\nlr_val = lr_model.predict_proba(X_val)[:,1]\nlr_test = lr_model.predict_proba(X_test)[:,1]\n\n# Blend predictions\nval_blend = (xgb_val + rf_val + lr_val) / 3\ntest_blend = (xgb_test + rf_test + lr_test) / 3\n\n# Find best validation threshold\nbest_thr, best_acc = 0.5, 0\nfor thr in np.linspace(0.3, 0.7, 101):\n    acc = accuracy_score(y_val, (val_blend > thr).astype(int))\n    if acc > best_acc: best_thr, best_acc = thr, acc\n\nprint(f'Best validation accuracy (ensemble): {best_acc:.4f} at threshold {best_thr:.3f}')\n\ny_pred = (test_blend > best_thr).astype(int)  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# y_pred= (preds > 0.5).astype(int)\ndf_pred = pd.DataFrame(y_pred, columns=['prediction'])\ndf_pred[\"id\"] = range(1, len(df_pred) + 1)\ndf_pred.to_csv('ypredl11.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}